{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/train.csv.zip')\n",
    "\n",
    "#allow all columns to be displayed\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the data, lets take a closer look at the data. We will look at the distribution of the data as well as the number of missing values and the type of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Data distibution and any bad values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.095844</td>\n",
       "      <td>0.009996</td>\n",
       "      <td>0.052948</td>\n",
       "      <td>0.002996</td>\n",
       "      <td>0.049364</td>\n",
       "      <td>0.008805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.294379</td>\n",
       "      <td>0.099477</td>\n",
       "      <td>0.223931</td>\n",
       "      <td>0.054650</td>\n",
       "      <td>0.216627</td>\n",
       "      <td>0.093420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               toxic   severe_toxic        obscene         threat  \\\n",
       "count  159571.000000  159571.000000  159571.000000  159571.000000   \n",
       "mean        0.095844       0.009996       0.052948       0.002996   \n",
       "std         0.294379       0.099477       0.223931       0.054650   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       0.000000       0.000000   \n",
       "75%         0.000000       0.000000       0.000000       0.000000   \n",
       "max         1.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "              insult  identity_hate  \n",
       "count  159571.000000  159571.000000  \n",
       "mean        0.049364       0.008805  \n",
       "std         0.216627       0.093420  \n",
       "min         0.000000       0.000000  \n",
       "25%         0.000000       0.000000  \n",
       "50%         0.000000       0.000000  \n",
       "75%         0.000000       0.000000  \n",
       "max         1.000000       1.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxic\n",
      "0    144277\n",
      "1     15294\n",
      "Name: count, dtype: int64\n",
      "toxic\n",
      "0    0.904156\n",
      "1    0.095844\n",
      "Name: proportion, dtype: float64\n",
      "severe_toxic\n",
      "0    157976\n",
      "1      1595\n",
      "Name: count, dtype: int64\n",
      "severe_toxic\n",
      "0    0.990004\n",
      "1    0.009996\n",
      "Name: proportion, dtype: float64\n",
      "obscene\n",
      "0    151122\n",
      "1      8449\n",
      "Name: count, dtype: int64\n",
      "obscene\n",
      "0    0.947052\n",
      "1    0.052948\n",
      "Name: proportion, dtype: float64\n",
      "threat\n",
      "0    159093\n",
      "1       478\n",
      "Name: count, dtype: int64\n",
      "threat\n",
      "0    0.997004\n",
      "1    0.002996\n",
      "Name: proportion, dtype: float64\n",
      "insult\n",
      "0    151694\n",
      "1      7877\n",
      "Name: count, dtype: int64\n",
      "insult\n",
      "0    0.950636\n",
      "1    0.049364\n",
      "Name: proportion, dtype: float64\n",
      "identity_hate\n",
      "0    158166\n",
      "1      1405\n",
      "Name: count, dtype: int64\n",
      "identity_hate\n",
      "0    0.991195\n",
      "1    0.008805\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "toxic_types = ['toxic',\t'severe_toxic'\t,'obscene',\t'threat',\t'insult', \t'identity_hate']\n",
    "\n",
    "#get the value counts for each toxic type\n",
    "for toxic_type in toxic_types:\n",
    "    print(df[toxic_type].value_counts())\n",
    "    print(df[toxic_type].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    143346\n",
      "1      6360\n",
      "3      4209\n",
      "2      3480\n",
      "4      1760\n",
      "5       385\n",
      "6        31\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    0.898321\n",
       "1    0.039857\n",
       "3    0.026377\n",
       "2    0.021808\n",
       "4    0.011030\n",
       "5    0.002413\n",
       "6    0.000194\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#find out how many of the rows have no toxic comments\n",
    "print(df[toxic_types].sum(axis=1).value_counts())\n",
    "df[toxic_types].sum(axis=1).value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see above, the majority of the data has been labeled as non-toxic. We may need to be careful about the model overfitting to just label non-toxic. We will need to look at the other labels to see if they are also skewed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1595, 8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "double_toxic=df[(df.toxic==1) & (df.severe_toxic==1)]\n",
    "double_toxic.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1595, 8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "severely_toxic = df[df.severe_toxic==1]\n",
    "severely_toxic.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "double_toxic.equals(severely_toxic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'comment_text', 'toxic', 'severe_toxic', 'obscene', 'threat',\n",
       "       'insult', 'identity_hate'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6155, 8)\n",
      "(7877, 8)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(8449, 8)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get all data with obscene and insult comments\n",
    "obscene_insult = df[(df.obscene==1) & (df.insult==1)]\n",
    "print(obscene_insult.shape)\n",
    "\n",
    "insult = df[df.insult==1]\n",
    "insult.shape\n",
    "print(insult.shape)\n",
    "\n",
    "\n",
    "#get all data with obscene  comments\n",
    "obscene = df[df.obscene==1]\n",
    "obscene.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly all the ones tagged as severe_toxic are also labelled as toxic. Also a lot of the obscene and insult comments are also frequently labelled together.  Perhaps it will be useful to look at some of the examples that are labelled as only one or the other To get a better idea for what defines that category of data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Looking at samples within the categories to get a better idea of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1722, 8)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#using df, get all data with obscene  comments and insult comments not equal to 1\n",
    "obscene_not_insult = df[(df.obscene==1) & (df.insult!=1)]\n",
    "obscene_not_insult.shape\n",
    "\n",
    "#using df, get all data with insult  comments not equal to 1\n",
    "insult_not_obscene = df[(df.obscene!=1) & (df.insult==1)]\n",
    "insult_not_obscene.shape\n",
    "\n",
    "#using df, get all data with obscene  comments and all other toxic types not equal to 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#look at a few of the comments in obscene_not_insult\n",
    "for item in obscene_not_insult.comment_text.head(10):\n",
    "    print(item)\n",
    "    print('------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxic_only shape:  (5666, 8)\n",
      "severe_toxic_only shape:  (0, 8)\n",
      "obscene_only shape:  (317, 8)\n",
      "threat_only shape:  (22, 8)\n",
      "insult_only shape:  (301, 8)\n",
      "identity_hate_only shape:  (54, 8)\n",
      "okay_only shape:  (143346, 8)\n"
     ]
    }
   ],
   "source": [
    "toxic_types = ['toxic',\t'severe_toxic'\t,'obscene',\t'threat',\t'insult', \t'identity_hate']\n",
    "#using df, get all data with obscene  comments and all other toxic types not equal to 1\n",
    "\n",
    "toxic_only = df[(df.toxic==1) & (df[toxic_types].sum(axis=1)==1)]\n",
    "print('toxic_only shape: ', toxic_only.shape)\n",
    "severe_toxic_only = df[(df.severe_toxic==1) & (df[toxic_types].sum(axis=1)==1)]\n",
    "print('severe_toxic_only shape: ', severe_toxic_only.shape)\n",
    "\n",
    "obscene_only = df[(df.obscene==1) & (df[toxic_types].sum(axis=1)==1)]\n",
    "print('obscene_only shape: ', obscene_only.shape)\n",
    "\n",
    "threat_only = df[(df.threat==1) & (df[toxic_types].sum(axis=1)==1)]\n",
    "print('threat_only shape: ', threat_only.shape)\n",
    "\n",
    "insult_only = df[(df.insult==1) & (df[toxic_types].sum(axis=1)==1)]\n",
    "print('insult_only shape: ', insult_only.shape)\n",
    "\n",
    "identity_hate_only = df[(df.identity_hate==1) & (df[toxic_types].sum(axis=1)==1)]\n",
    "print('identity_hate_only shape: ', identity_hate_only.shape)\n",
    "\n",
    "okay_only = df[(df[toxic_types].sum(axis=1)==0)]\n",
    "print('okay_only shape: ', okay_only.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for text in toxic_only.comment_text.head(10):\n",
    "    print(text)\n",
    "    print('------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nothing too clear to distinguish about this data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for text in obscene_only.comment_text.head(10):\n",
    "    print(text)\n",
    "    print('------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obscene comments seem to include heavily gaslighting, complaining, and blaming others for something they are probably responsible for.  Peoeple that exhibit these behaviors tend to narcissitic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More insights may be made but the time it takes to more closer evaluate the data before geting some sort of a bench mark doesnt not seem helpful"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Moving onto model training  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a lesson learned - multilabel data split\n",
    "\n",
    "A classic stratified split does not work with multilablled data when there are rare multilabeleed instances that only occur once in the dataset.  As a result, I found that rare data and removed it before doing the test/train split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(127655, 9) (31914, 9)\n"
     ]
    }
   ],
   "source": [
    "#first we need to split the data into train and validation sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#split the data into train and validation sets\n",
    "train, valid = train_test_split(df, test_size=0.2, random_state=42, stratify=df[toxic_types], )\n",
    "\n",
    "print(train.shape, valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>multi_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate multi_label  \n",
       "0             0        0       0       0              0          []  \n",
       "1             0        0       0       0              0          []  \n",
       "2             0        0       0       0              0          []  \n",
       "3             0        0       0       0              0          []  \n",
       "4             0        0       0       0              0          []  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#make a column called multi_label that is the list of all the valid labels column names\n",
    "df['multi_label'] = df[toxic_types].apply(lambda x: x.index[x==1].tolist(), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if its an empty list, make it a list with one item, 'non-toxic'\n",
    "df['multi_label'] = df['multi_label'].apply(lambda x: x if len(x)>0 else ['non-toxic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "multi_label\n",
       "[non-toxic]                                                      143346\n",
       "[toxic]                                                            5666\n",
       "[toxic, obscene, insult]                                           3800\n",
       "[toxic, obscene]                                                   1758\n",
       "[toxic, insult]                                                    1215\n",
       "[toxic, severe_toxic, obscene, insult]                              989\n",
       "[toxic, obscene, insult, identity_hate]                             618\n",
       "[obscene]                                                           317\n",
       "[insult]                                                            301\n",
       "[toxic, severe_toxic, obscene, insult, identity_hate]               265\n",
       "[obscene, insult]                                                   181\n",
       "[toxic, severe_toxic, obscene]                                      158\n",
       "[toxic, identity_hate]                                              136\n",
       "[toxic, insult, identity_hate]                                      134\n",
       "[toxic, obscene, threat, insult]                                    131\n",
       "[toxic, threat]                                                     113\n",
       "[toxic, severe_toxic, obscene, threat, insult]                       64\n",
       "[toxic, obscene, threat, insult, identity_hate]                      56\n",
       "[identity_hate]                                                      54\n",
       "[toxic, severe_toxic]                                                41\n",
       "[toxic, obscene, identity_hate]                                      35\n",
       "[toxic, severe_toxic, obscene, threat, insult, identity_hate]        31\n",
       "[insult, identity_hate]                                              28\n",
       "[threat]                                                             22\n",
       "[obscene, insult, identity_hate]                                     18\n",
       "[toxic, threat, insult]                                              16\n",
       "[toxic, severe_toxic, insult]                                        14\n",
       "[toxic, obscene, threat]                                             11\n",
       "[toxic, severe_toxic, threat]                                        11\n",
       "[toxic, threat, identity_hate]                                        7\n",
       "[toxic, severe_toxic, insult, identity_hate]                          7\n",
       "[toxic, severe_toxic, obscene, identity_hate]                         6\n",
       "[toxic, severe_toxic, obscene, threat]                                4\n",
       "[threat, insult]                                                      3\n",
       "[toxic, threat, insult, identity_hate]                                3\n",
       "[toxic, severe_toxic, identity_hate]                                  3\n",
       "[obscene, identity_hate]                                              3\n",
       "[obscene, threat]                                                     2\n",
       "[obscene, threat, insult]                                             2\n",
       "[toxic, severe_toxic, threat, insult]                                 1\n",
       "[toxic, severe_toxic, threat, identity_hate]                          1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.multi_label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 9)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "condition1 = (df['toxic'] == 1) & (df['severe_toxic'] == 1) & (df['threat'] == 1) & (df['insult'] == 1)\n",
    "condition2 = (df['toxic'] == 1) & (df['severe_toxic'] == 1) & (df['threat'] == 1) & (df['identity_hate'] == 1)\n",
    "\n",
    "#find all the rows that have include conditions 1 or 2 and do not include any other toxic types\n",
    "df[(condition1 | condition2) & (df[toxic_types].sum(axis=1)==4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "rare_data = df[(condition1 | condition2) & (df[toxic_types].sum(axis=1)==4)]\n",
    "#drop the rare data from the df\n",
    "df = df.drop(rare_data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, valid = train_test_split(df, test_size=0.2, random_state=42, stratify=df['multi_label'], )\n",
    "#add the rare data df to the train set df\n",
    "train = pd.concat([train, rare_data])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a model\n",
    "\n",
    "For base evaluation, I will start off using a simpler model\n",
    "\n",
    "Afterwards, I will move onto training a large model, and maybe even a transformer model\n",
    "\n",
    "NOTE:  since the competition is over I could use the labelled test set but I will continue using the validation set to simulate a realistic competition"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clinical_assertion_pipeline",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
