{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessed Submissions\n",
    "\n",
    "Purpose: We want to see if the preprocessing alone has any improvements prior to feature selection/engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key findings so far:\n",
    "\n",
    "Data-related:\n",
    "- **imputation**: clipping and filling nulls with mean  \n",
    "- **encoding**: one-hot encoding\n",
    "- **validation scores**: more reliable after performing stratified split\n",
    "\n",
    "Model-related:\n",
    "- **baseline**: logistic regression is best baseline model\n",
    "- **advanced model**: random forest performs better than baseline model, but takes 45 mins to train on full dataset\n",
    "- **heuristic baseline**: median value is **BEST SCORE SO FAR! -- 1.10815** \n",
    "\n",
    "\n",
    "### Findings in this NB:\n",
    "#### Simple models\n",
    "- training a linear regression model after applying transforms + stardarized X features and transformed Y performed better results (closest to *heuristic baseline* with a score of **1.15**)\n",
    "- training with only applying preprocessing to the X features and NOT the y column had a worse score than the baseline model with only imputed data\n",
    "\n",
    "#### Advanced Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import numpy as np\n",
    "from scipy.stats import skew\n",
    "\n",
    "# Explicitly define the target column\n",
    "target_column = 'Premium Amount'\n",
    "\n",
    "test_data = pd.read_csv(\"../data/raw_dataset/test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Training the simple baseline models with standardized data\n",
    "(we specifically standardized the data for these models since they perform best/expect this distribution)\n",
    "\n",
    "Best steps to apply:\n",
    "\n",
    "- do a stratitied split when validating\n",
    "- be sure to apply reverse log when generating submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = pd.read_csv(\"../data/04_standardized_preprocessed_dataset.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## validating on a stratified split\n",
    "\n",
    "Looking at MSE and MAE It seems that this is doing much better than our training runs using the baseline dataset on these simple models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin Linear Regression training\n",
      "Linear Regression training complete\n",
      "begin Ridge Regression training\n",
      "Ridge Regression training complete\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>MSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>R^2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>1.135128e+06</td>\n",
       "      <td>848.895180</td>\n",
       "      <td>0.007794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ridge Regression</td>\n",
       "      <td>1.135128e+06</td>\n",
       "      <td>848.895181</td>\n",
       "      <td>0.007794</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Model           MSE         MAE       R^2\n",
       "0  Linear Regression  1.135128e+06  848.895180  0.007794\n",
       "1   Ridge Regression  1.135128e+06  848.895181  0.007794"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separate features (X) and target (y)\n",
    "X = train_dataset.drop(columns=[target_column])\n",
    "y = train_dataset[target_column]\n",
    "\n",
    "# Bin the target variable\n",
    "n_bins = 20\n",
    "bin_col = \"y_bin\"\n",
    "y_binned = pd.qcut(y, q=n_bins, duplicates='drop', labels=False)\n",
    "X[bin_col] = y_binned\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify= X[\"y_bin\"])\n",
    "\n",
    "#remove the stratification column\n",
    "X_test = X_test.drop(columns=[bin_col])\n",
    "X_train = X_train.drop(columns=[bin_col])\n",
    "\n",
    "# Define baseline models\n",
    "models = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Ridge Regression\": Ridge(),\n",
    "    # \"Decision Tree\": DecisionTreeRegressor(),\n",
    "}\n",
    "\n",
    "# Train and evaluate each model\n",
    "results = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"begin {name} training\")\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Evaluate performance\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    # Store results\n",
    "    results.append({\n",
    "        \"Model\": name,\n",
    "        \"MSE\": mse,\n",
    "        \"MAE\": mae,\n",
    "        \"R^2\": r2\n",
    "    })\n",
    "    print(f\"{name} training complete\")\n",
    "\n",
    "\n",
    "# Display results\n",
    "results_df = pd.DataFrame(results).sort_values(by=\"R^2\", ascending=False)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## retraining on full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin Linear Regression training\n"
     ]
    }
   ],
   "source": [
    "# Separate features (X) and target (y)\n",
    "X = train_dataset.drop(columns=[target_column])\n",
    "y = train_dataset[target_column]\n",
    "\n",
    "# Define baseline full_models\n",
    "full_models = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "}\n",
    "\n",
    "# Train and evaluate each model\n",
    "full_results = []\n",
    "\n",
    "for name, model in full_models.items():\n",
    "    print(f\"begin {name} training\")\n",
    "    # Train the model\n",
    "    model.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_test = test_data.copy()\n",
    "\n",
    "\n",
    "#minimally process the test dataset to get model predictions\n",
    "\n",
    "#convert the policy start time to duration in mins\n",
    "linear_test['Policy Start Date'] = pd.to_datetime(linear_test['Policy Start Date'])\n",
    "linear_test['Policy Duration Mins'] = ((pd.Timestamp.now() - linear_test['Policy Start Date']).dt.total_seconds())/60\n",
    "linear_test = linear_test.drop(columns=['Policy Start Date'])\n",
    "\n",
    "#do label encoding\n",
    "categorical_cols = [linear_test.columns[i] for i, x in enumerate(linear_test.dtypes) if x == 'object']\n",
    "linear_test[categorical_cols] = linear_test[categorical_cols].astype('category')\n",
    "# Convert categorical to one hot encodings\n",
    "linear_test = pd.get_dummies(linear_test, drop_first=True)\n",
    "#fill nulls with mean values\n",
    "linear_test = linear_test.fillna(X.mean())\n",
    "\n",
    "X_test = linear_test.iloc[:,1:]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed Age 0 time(s). Final skew: -0.24\n",
      "Transformed Annual Income 3 time(s). Final skew: -0.07\n",
      "Transformed Number of Dependents 0 time(s). Final skew: 0.13\n",
      "Transformed Health Score 0 time(s). Final skew: 0.12\n",
      "Transformed Previous Claims 2 time(s). Final skew: 0.47\n",
      "Transformed Vehicle Age 0 time(s). Final skew: -0.02\n",
      "Transformed Credit Score 1 time(s). Final skew: 0.06\n",
      "Transformed Insurance Duration 0 time(s). Final skew: -0.01\n",
      "Transformed Policy Duration Mins 0 time(s). Final skew: -0.00\n"
     ]
    }
   ],
   "source": [
    "\n",
    "###############################\n",
    "#apply the transformations and standardization\n",
    "non_binary_cols = [col for col in X_test.columns if X_test[col].dtype != 'bool']\n",
    "\n",
    "# Apply transformations iteratively until skew is within [-0.5, 0.5]\n",
    "for col in non_binary_cols:\n",
    "    max_iterations = 3  # Prevent excessive loops\n",
    "    iteration = 0\n",
    "\n",
    "    while iteration < max_iterations:\n",
    "        skew_value = skew(X_test[col])\n",
    "        if -0.5 <= skew_value <= 0.5:\n",
    "            break  # Stop if skew is already in range\n",
    "        \n",
    "        if skew_value > 0.5:\n",
    "            X_test[col] = np.log1p(X_test[col])  # Log transform for positive skew\n",
    "        elif skew_value < -0.5:\n",
    "            X_test[col] = X_test[col]**2  # Square for negative skew\n",
    "            \n",
    "        iteration += 1\n",
    "    \n",
    "    final_skew = skew(X_test[col])\n",
    "    print(f\"Transformed {col} {iteration} time(s). Final skew: {final_skew:.2f}\")\n",
    "\n",
    "\n",
    "\n",
    "# Perform Z-score standardization for non-binary columns\n",
    "for col in non_binary_cols:\n",
    "    mean = X_test[col].mean()\n",
    "    std = X_test[col].std()\n",
    "    X_test[col] = (X_test[col] - mean) / std\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### predict and submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitting file: ../results\\Linear Regression_standardized_preprocessing.csv to competition: playground-series-s4e12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20.6M/20.6M [00:20<00:00, 1.06MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission to 'playground-series-s4e12' successful!\n"
     ]
    }
   ],
   "source": [
    "#generate results and submit to competition\n",
    "results_directory = \"../results\"\n",
    "\n",
    "for name, model in full_models.items():\n",
    "    \n",
    "    y_pred = np.expm1(np.sqrt(np.sqrt(model.predict(X_test)))) #model.predict(X_test)#\n",
    "\n",
    "    results = pd.DataFrame({\n",
    "        'id': linear_test['id'],  \n",
    "        'Premium Amount': y_pred   \n",
    "    })\n",
    "\n",
    "    filename = f\"{name}_standardized_preprocessing.csv\"\n",
    "    results_full_path = os.path.join(results_directory,filename)\n",
    "    \n",
    "    results.to_csv(results_full_path, index=False)\n",
    "\n",
    "    submission_comment = f\"{name} with clipping and mean imputed values\"\n",
    "    kg_utils.submit(filename,submission_comment) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latest submission 'Linear Regression_standardized_preprocessing.csv' score: 1.11532\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1.11532'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kg_utils.get_latest_score()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Training Advanced model with normalized data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
